{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwpd0FlyuMUV",
        "outputId": "8b49629a-0414-40d3-82d1-02e8b327088a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.util import ngrams\n",
        "import transformers\n",
        "from datetime import datetime\n",
        "import json\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "#import spacy\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "ts= datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "output_dir = f'/content/drive/My Drive/Colab Notebooks/output/{ts}'\n",
        "os.makedirs(f\"{output_dir}\",exist_ok=True)\n",
        "\n",
        "!pip install pyLDAvis\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3XAztLCqUlU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "489cb42d-0f38-4499-8797-69bb8b4c3deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.0\n",
            "    Uninstalling numpy-1.26.0:\n",
            "      Successfully uninstalled numpy-1.26.0\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#1) Downgrade NumPy to 1.26.x\n",
        "!pip install numpy==1.26.0 --upgrade\n",
        "\n",
        "# 2) Force-reinstall Gensim so it compiles against the new NumPy\n",
        "!pip install --upgrade --force-reinstall gensim\n",
        "\n",
        "# !pip install  gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TyVmX6-5vFlc"
      },
      "outputs": [],
      "source": [
        "## loading df that has data for the specific periods of interest     ('2020-01-01', '2020-05-31'),('2020-10-01', '2021-01-31'),('2021-11-01', '2022-01-31'),('2022-11-01','2023-01-31')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5A5UQYFZyu4a"
      },
      "outputs": [],
      "source": [
        "# Specify the path including the folder in your Google Drive\n",
        "path = '/content/drive/My Drive/Colab Notebooks/selected_df.csv'\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "laiq0eWIoqv5",
        "outputId": "2b43a75a-2d1a-408a-f7c5-4ac49e3698db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  created_utc     label     score  \\\n",
              "0  2020-05-31  mild neu  0.569819   \n",
              "1  2020-05-31  mild neu  0.617377   \n",
              "2  2020-05-31  mild neu  0.610706   \n",
              "3  2020-05-31  mild neu  0.576460   \n",
              "4  2020-05-31  mild neu  0.629136   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0                                ill pay mosaic much  \n",
              "1  redemption november right riding shoe either m...  \n",
              "2  sure planning hilton redemption soon wouldnt s...  \n",
              "3                                             thanks  \n",
              "4                                           bigger w  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdde19cc-7566-4de5-ac52-194217b6d611\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>mild neu</td>\n",
              "      <td>0.569819</td>\n",
              "      <td>ill pay mosaic much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>mild neu</td>\n",
              "      <td>0.617377</td>\n",
              "      <td>redemption november right riding shoe either m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>mild neu</td>\n",
              "      <td>0.610706</td>\n",
              "      <td>sure planning hilton redemption soon wouldnt s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>mild neu</td>\n",
              "      <td>0.576460</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>mild neu</td>\n",
              "      <td>0.629136</td>\n",
              "      <td>bigger w</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdde19cc-7566-4de5-ac52-194217b6d611')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdde19cc-7566-4de5-ac52-194217b6d611 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdde19cc-7566-4de5-ac52-194217b6d611');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3b5a8f25-8566-4c5c-b0ab-6120b78ad85c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b5a8f25-8566-4c5c-b0ab-6120b78ad85c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3b5a8f25-8566-4c5c-b0ab-6120b78ad85c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 87034,\n  \"fields\": [\n    {\n      \"column\": \"created_utc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 422,\n        \"samples\": [\n          \"2021-01-30\",\n          \"2021-11-24\",\n          \"2020-12-31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"mild neu\",\n          \"high neu\",\n          \"high neg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12152225759342901,\n        \"min\": 0.4403473436832428,\n        \"max\": 0.992438018321991,\n        \"num_unique_values\": 77047,\n        \"samples\": [\n          0.8842844367027283,\n          0.7468905448913574,\n          0.6949559450149536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 77616,\n        \"samples\": [\n          \"definitely day hilo fancy beautiful old hawaii feel\",\n          \"right thought aspire actually surpass card well worth annual fee stay night year\",\n          \"totally agree dont want run problem registration hotel american russian tourist visa need apologize thanks community kind\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS0uOK5LpFpY",
        "outputId": "4dd928d1-2499-4c09-b02a-a658d86a2788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DWqGfdx6prB_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import nltk\n",
        "# nltk.download('punkt_tab')\n",
        "# !pip install -U spacy torch transformers\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "p-n91NfcK6X-"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy download en_core_web_trf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15z4DtWGq2sb",
        "outputId": "8a8b5bf8-1353-428d-cf6a-c437e0d56d75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87034"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOAsdno1q0R6",
        "outputId": "0bfd977a-e3fa-4efe-a50d-2a94a01109d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86446"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#drop NA\n",
        "# drop any rows where cleaned_text isn’t a real string\n",
        "df = df.dropna(subset=['cleaned_text'])\n",
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OxBuDUtVoeDw",
        "outputId": "eaae8db8-0705-423a-bdb1-17930ea1cb00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  created_utc     score                                         final_text  \\\n",
              "0  2020-05-31  0.569819                                     ill pay mosaic   \n",
              "1  2020-05-31  0.617377  redemption november right riding shoe move tri...   \n",
              "2  2020-05-31  0.610706  sure plan hilton redemption soon speculatively...   \n",
              "3  2020-05-31  0.576460                                              thank   \n",
              "4  2020-05-31  0.629136                                                big   \n",
              "\n",
              "                                              tokens  \n",
              "0                                 [ill, pay, mosaic]  \n",
              "1  [redemption, november, right, riding, shoe, mo...  \n",
              "2  [sure, plan, hilton, redemption, soon, specula...  \n",
              "3                                            [thank]  \n",
              "4                                              [big]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-076cd73c-0b8c-4eb2-a6b9-739beffc489b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>score</th>\n",
              "      <th>final_text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>0.569819</td>\n",
              "      <td>ill pay mosaic</td>\n",
              "      <td>[ill, pay, mosaic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>0.617377</td>\n",
              "      <td>redemption november right riding shoe move tri...</td>\n",
              "      <td>[redemption, november, right, riding, shoe, mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>0.610706</td>\n",
              "      <td>sure plan hilton redemption soon speculatively...</td>\n",
              "      <td>[sure, plan, hilton, redemption, soon, specula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>0.576460</td>\n",
              "      <td>thank</td>\n",
              "      <td>[thank]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>0.629136</td>\n",
              "      <td>big</td>\n",
              "      <td>[big]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-076cd73c-0b8c-4eb2-a6b9-739beffc489b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-076cd73c-0b8c-4eb2-a6b9-739beffc489b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-076cd73c-0b8c-4eb2-a6b9-739beffc489b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3fe1c492-9014-4cbf-a448-5190a84dd63c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fe1c492-9014-4cbf-a448-5190a84dd63c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3fe1c492-9014-4cbf-a448-5190a84dd63c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['created_utc','score','final_text','tokens']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"created_utc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-05-31 00:00:00\",\n        \"max\": \"2020-05-31 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2020-05-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026115351458423277,\n        \"min\": 0.5698192715644836,\n        \"max\": 0.6291364431381226,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6173766851425171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"redemption november right riding shoe move trip availability cancel let point sit cash transfer hilton come massive loss november roll dice rebook\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "## Data Cleaning with spaCy\n",
        "import re, string\n",
        "import pandas as pd\n",
        "import contractions\n",
        "import spacy\n",
        "\n",
        "# Load spaCy's English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# nlp = spacy.load(\"en_core_web_trf\")\n",
        "# Convert timestamp column\n",
        "df['created_utc'] = pd.to_datetime(df['created_utc'])\n",
        "\n",
        "# Define full-clean function using spaCy\n",
        "def full_clean_spacy(doc):\n",
        "    # Basic regex cleaning\n",
        "    doc = re.sub(r'\\s+', ' ', doc).strip()\n",
        "    doc = doc.lower()\n",
        "    doc = re.sub(r'http\\S+|www\\.\\S+', '', doc)\n",
        "    doc = re.sub(r'<.*?>',          '', doc)\n",
        "    doc = re.sub(r'@\\w+|#\\w+',      '', doc)\n",
        "    doc = contractions.fix(doc)\n",
        "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
        "    doc = re.sub(r'\\d+', '', doc)\n",
        "\n",
        "    # Process with spaCy\n",
        "    spacy_doc = nlp(doc)\n",
        "\n",
        "    # Lemmatize, remove stopwords and short tokens\n",
        "    tokens = [\n",
        "        token.lemma_\n",
        "        for token in spacy_doc\n",
        "        if not token.is_stop and not token.is_punct and len(token) > 2\n",
        "    ]\n",
        "    return tokens\n",
        "\n",
        "# Apply to each row\n",
        "df['tokens']     = df['cleaned_text'].apply(full_clean_spacy)\n",
        "df['final_text'] = df['tokens'].str.join(' ')\n",
        "\n",
        "# Preview\n",
        "df[['created_utc','score','final_text','tokens']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1Qd-mQhrDzG",
        "outputId": "b01e86e7-d713-4049-93bd-a54009f5c4e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86446"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "qtaS7KFiz2j9",
        "outputId": "7b93944d-66e8-4084-ac68-bc6317851a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-49ea9e575302>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  high_pos_df['created_utc'] = pd.to_datetime(high_pos_df['created_utc'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      created_utc     label     score  \\\n",
              "63040  2023-01-02  mild pos  0.577042   \n",
              "63091  2023-01-02  mild pos  0.667171   \n",
              "63110  2023-01-01  mild pos  0.736473   \n",
              "63128  2023-01-01  mild pos  0.664399   \n",
              "63164  2023-01-01  mild pos  0.722994   \n",
              "\n",
              "                                            cleaned_text  \\\n",
              "63040  flown disagree supposed fall asleep right away...   \n",
              "63091  application approved global entry tried make a...   \n",
              "63110  dallas isnt walkable short uber almost everyth...   \n",
              "63128  really system designed weed thing considered x...   \n",
              "63164  able book eventually successful australian cal...   \n",
              "\n",
              "                                                  tokens  \\\n",
              "63040  [fly, disagree, suppose, fall, asleep, right, ...   \n",
              "63091  [application, approve, global, entry, try, app...   \n",
              "63110  [dallas, walkable, short, uber, restaurant, ho...   \n",
              "63128  [system, design, weed, thing, consider, value,...   \n",
              "63164  [able, book, eventually, successful, australia...   \n",
              "\n",
              "                                              final_text  \n",
              "63040  fly disagree suppose fall asleep right away ea...  \n",
              "63091  application approve global entry try appointme...  \n",
              "63110  dallas walkable short uber restaurant hotel ca...  \n",
              "63128  system design weed thing consider value chase ...  \n",
              "63164  able book eventually successful australian center  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f0960a8-2569-40e3-bc08-bafe3fd9e868\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>final_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63040</th>\n",
              "      <td>2023-01-02</td>\n",
              "      <td>mild pos</td>\n",
              "      <td>0.577042</td>\n",
              "      <td>flown disagree supposed fall asleep right away...</td>\n",
              "      <td>[fly, disagree, suppose, fall, asleep, right, ...</td>\n",
              "      <td>fly disagree suppose fall asleep right away ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63091</th>\n",
              "      <td>2023-01-02</td>\n",
              "      <td>mild pos</td>\n",
              "      <td>0.667171</td>\n",
              "      <td>application approved global entry tried make a...</td>\n",
              "      <td>[application, approve, global, entry, try, app...</td>\n",
              "      <td>application approve global entry try appointme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63110</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>mild pos</td>\n",
              "      <td>0.736473</td>\n",
              "      <td>dallas isnt walkable short uber almost everyth...</td>\n",
              "      <td>[dallas, walkable, short, uber, restaurant, ho...</td>\n",
              "      <td>dallas walkable short uber restaurant hotel ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63128</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>mild pos</td>\n",
              "      <td>0.664399</td>\n",
              "      <td>really system designed weed thing considered x...</td>\n",
              "      <td>[system, design, weed, thing, consider, value,...</td>\n",
              "      <td>system design weed thing consider value chase ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63164</th>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>mild pos</td>\n",
              "      <td>0.722994</td>\n",
              "      <td>able book eventually successful australian cal...</td>\n",
              "      <td>[able, book, eventually, successful, australia...</td>\n",
              "      <td>able book eventually successful australian center</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f0960a8-2569-40e3-bc08-bafe3fd9e868')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f0960a8-2569-40e3-bc08-bafe3fd9e868 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f0960a8-2569-40e3-bc08-bafe3fd9e868');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2b221ed9-f62e-403a-a2a9-642ff4749c1f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b221ed9-f62e-403a-a2a9-642ff4749c1f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2b221ed9-f62e-403a-a2a9-642ff4749c1f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "high_pos_df",
              "summary": "{\n  \"name\": \"high_pos_df\",\n  \"rows\": 1582,\n  \"fields\": [\n    {\n      \"column\": \"created_utc\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-11-01 00:00:00\",\n        \"max\": \"2023-01-02 00:00:00\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"2022-11-02 00:00:00\",\n          \"2022-11-06 00:00:00\",\n          \"2023-01-02 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mild pos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0566932920694335,\n        \"min\": 0.4522937536239624,\n        \"max\": 0.7499756217002869,\n        \"num_unique_values\": 1539,\n        \"samples\": [\n          0.7491581439971924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1543,\n        \"samples\": [\n          \"ill absolutely wear mask one good thing come pandemic way normal put mask feeling well\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1535,\n        \"samples\": [\n          \"good time book flight plan going begin july faq month prior mark maybe summer holiday month prior eye open price like\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Filter the DataFrame\n",
        "high_pos_df = df[df['label'] == 'mild pos']\n",
        "\n",
        "# Convert the 'created_utc' column to datetime\n",
        "high_pos_df['created_utc'] = pd.to_datetime(high_pos_df['created_utc'])\n",
        "\n",
        "# Define your date range\n",
        "# start_date = '2020-10-01'\n",
        "# end_date = '2021-01-31'\n",
        "# start_date = '2021-11-01'\n",
        "# end_date = '2022-01-31'\n",
        "\n",
        "start_date = '2022-11-01'\n",
        "end_date = '2023-01-31'\n",
        "# Filter the DataFrame for entries within the specified date range\n",
        "high_pos_df = high_pos_df[(high_pos_df['created_utc'] >= start_date) & (high_pos_df['created_utc'] <= end_date)]\n",
        "\n",
        "\n",
        "# Print the filtered DataFrame to check the result\n",
        "high_pos_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD7b88xcsjCs",
        "outputId": "3832bf6e-0e80-43e7-d88d-386e7ad57b45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1582"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "high_pos_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iH7YFf16slT_",
        "outputId": "0e71f3c6-978f-4d1e-92e0-3c9155ac84f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       token  count\n",
            "0       good    496\n",
            "1     flight    492\n",
            "2      point    408\n",
            "3       book    323\n",
            "4      thank    269\n",
            "5       like    266\n",
            "6        fly    257\n",
            "7       well    246\n",
            "8       time    236\n",
            "9       look    186\n",
            "10   airline    182\n",
            "11     think    180\n",
            "12    travel    178\n",
            "13      find    174\n",
            "14       day    167\n",
            "15       way    163\n",
            "16  business    162\n",
            "17      seat    156\n",
            "18     great    150\n",
            "19      trip    149\n",
            "20        go    148\n",
            "21       get    142\n",
            "22     hotel    137\n",
            "23      mile    135\n",
            "24      know    130\n",
            "25      year    129\n",
            "26      want    129\n",
            "27     class    125\n",
            "28     check    121\n",
            "29    ticket    120\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Flatten your tokens into one long list\n",
        "all_tokens = [t for toks in high_pos_df['tokens'] for t in toks]\n",
        "\n",
        "# 2) Build a frequency distribution\n",
        "freq = Counter(all_tokens)\n",
        "common = freq.most_common(30)   # top 30\n",
        "\n",
        "# 3) Turn it into a DataFrame for easy inspection\n",
        "df_freq = pd.DataFrame(common, columns=['token','count'])\n",
        "print(df_freq)\n",
        "\n",
        "# 4) Plot a simple bar chart of the top tokens\n",
        "tokens, counts = zip(*common)\n",
        "plt.figure()\n",
        "plt.bar(tokens, counts)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Token')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 30 Tokens in high_pos_df')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrNou6iFoQTq",
        "outputId": "c74fe08a-bf5d-4a19-f36b-d1c303c0c345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30429 words total, with a vocabulary size of 4377\n",
            "Max reddit post length is 166 tokens\n",
            "Mean reddit post length is 19.23 tokens\n",
            "Median reddit post length is 13 tokens\n"
          ]
        }
      ],
      "source": [
        "# Flatten all tokens into one list\n",
        "all_words   = [word for tokens in high_pos_df['tokens'] for word in tokens]\n",
        "\n",
        "# Compute the length (in tokens) of each post\n",
        "post_length = [len(tokens) for tokens in high_pos_df['tokens']]\n",
        "\n",
        "# Build the vocabulary\n",
        "vocab       = sorted(set(all_words))\n",
        "\n",
        "# Print your summary stats\n",
        "print(f\"{len(all_words)} words total, with a vocabulary size of {len(vocab)}\")\n",
        "print(f\"Max reddit post length is {max(post_length)} tokens\")\n",
        "print(f\"Mean reddit post length is {sum(post_length)/len(post_length):.2f} tokens\")\n",
        "print(f\"Median reddit post length is {sorted(post_length)[len(post_length)//2]} tokens\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "JokXufzvpthU",
        "outputId": "5f1e6b4a-93d3-47ea-8c21-3e019cd8ef90"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "sns.histplot(post_length, bins=60, kde=True)\n",
        "plt.title('Post Length Distribution', fontsize=18)\n",
        "plt.xlabel('Words per Post', fontsize=12)\n",
        "plt.ylabel('Number of Posts', fontsize=12)\n",
        "# Setting x-axis ticks and labels for more detail\n",
        "max_length = max(post_length)\n",
        "xticks = np.arange(0, max_length + 1, max_length // 60)\n",
        "plt.xticks(xticks)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "n1yeytbRvYKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a042359a-c660-4215-ece2-530e74e87e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#1) Downgrade NumPy to 1.26.x\n",
        "# !pip install numpy==1.26.0 --upgrade\n",
        "\n",
        "# # 2) Force-reinstall Gensim so it compiles against the new NumPy\n",
        "# !pip install --upgrade --force-reinstall gensim\n",
        "\n",
        "!pip install  gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "QpM_ionbojQt",
        "outputId": "5e59f2a7-1540-4357-93ce-7491aa204ecb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-fd2a5484ab5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphrases\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhraser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1) Prepare your list-of-lists from the `tokens` column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/corpora/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[0;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/corpora/indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;31m# try to load fast, cythonized code if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/_matutils.pyx\u001b[0m in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "# 1) Prepare your list-of-lists from the `tokens` column\n",
        "texts = high_pos_df['tokens'].tolist()\n",
        "\n",
        "#    min_count=3 → only consider pairs that appear in ≥3 docs\n",
        "#    threshold=50 → higher threshold = fewer, more confident bigrams\n",
        "# 2) Train the bigram detector\n",
        "bigram = Phrases(texts, min_count=3, threshold=50)\n",
        "bigram_mod = Phraser(bigram)\n",
        "\n",
        "# 3) Train the trigram detector on the bigram-transformed texts\n",
        "trigram = Phrases(bigram[texts], min_count=2, threshold=150)\n",
        "trigram_mod = Phraser(trigram)\n",
        "\n",
        "# 4) Apply bigram and trigram transforms\n",
        "high_pos_df['bigram_tokens']   = high_pos_df['tokens'].apply(lambda doc: bigram_mod[doc])\n",
        "high_pos_df['trigram_tokens']  = high_pos_df['tokens'].apply(lambda doc: trigram_mod[bigram_mod[doc]])\n",
        "\n",
        "# # 5) (Optional) If you need back a single string for vectorizers:\n",
        "# high_pos_df['bigram_text']   = high_pos_df['bigram_tokens'].str.join(' ')\n",
        "# high_pos_df['trigram_text']  = high_pos_df['trigram_tokens'].str.join(' ')\n",
        "\n",
        "# 6) Inspect\n",
        "print(high_pos_df[['tokens','bigram_tokens','trigram_tokens']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZQn2MSqp1f9"
      },
      "outputs": [],
      "source": [
        "# 1) Helper to detect n-grams in a token list\n",
        "def contains_ngram(tokenized_list, n):\n",
        "    return any(len(tok.split('_')) == n for tok in tokenized_list)\n",
        "\n",
        "# 2) Flag rows\n",
        "high_pos_df['has_bigrams']  = high_pos_df['bigram_tokens'].apply(lambda doc: contains_ngram(doc, 2))\n",
        "high_pos_df['has_trigrams'] = high_pos_df['trigram_tokens'].apply(lambda doc: contains_ngram(doc, 3))\n",
        "\n",
        "# 3) Count\n",
        "rows_with_bigrams  = high_pos_df['has_bigrams'].sum()\n",
        "rows_with_trigrams = high_pos_df['has_trigrams'].sum()\n",
        "rows_with_none     = (~high_pos_df['has_bigrams'] & ~high_pos_df['has_trigrams']).sum()\n",
        "\n",
        "# 4) Report\n",
        "print(f\"Rows with bigrams:   {rows_with_bigrams}\")\n",
        "print(f\"Rows with trigrams:  {rows_with_trigrams}\")\n",
        "print(f\"Rows with no n-grams: {rows_with_none}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "negWzwRYz_W-"
      },
      "outputs": [],
      "source": [
        "high_pos_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ccUmhjy9yX"
      },
      "outputs": [],
      "source": [
        "# Print the total number of rows in the DataFrame\n",
        "total_rows = high_pos_df.shape[0]\n",
        "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
        "\n",
        "# Check the number of rows in the 'trigram_tokenized' column\n",
        "print(f\"Number of rows in 'trigram_tokenized' column: {high_pos_df['trigram_tokens'].shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CnA4ROfW6Oq"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# 1) Flatten all trigram lists into one big sequence\n",
        "all_bigrams = itertools.chain.from_iterable(high_pos_df['bigram_tokens'])\n",
        "\n",
        "# 2) Filter for genuine trigrams (exactly two underscores → three words joined)\n",
        "bigram_counts = Counter(\n",
        "    token for token in all_bigrams\n",
        "    if isinstance(token, str) and token.count('_') == 1\n",
        ")\n",
        "\n",
        "# 3) How many unique trigrams?\n",
        "total_unique_bigrams = len(bigram_counts)\n",
        "print(f\"Total number of unique bigrams: {total_unique_bigrams}\")\n",
        "\n",
        "# 4) Show the 10 most common trigrams\n",
        "print(\"\\nMost common bigrams:\")\n",
        "for bigram, count in bigram_counts.most_common(10):\n",
        "    print(f\"{bigram}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT_nVWWxg2pW"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# 1) Flatten all trigram lists into one big sequence\n",
        "all_trigrams = itertools.chain.from_iterable(high_pos_df['trigram_tokens'])\n",
        "\n",
        "# 2) Filter for genuine trigrams (exactly two underscores → three words joined)\n",
        "trigram_counts = Counter(\n",
        "    token for token in all_trigrams\n",
        "    if isinstance(token, str) and token.count('_') == 2\n",
        ")\n",
        "\n",
        "# 3) How many unique trigrams?\n",
        "total_unique_trigrams = len(trigram_counts)\n",
        "print(f\"Total number of unique trigrams: {total_unique_trigrams}\")\n",
        "\n",
        "# 4) Show the 10 most common trigrams\n",
        "print(\"\\nMost common trigrams:\")\n",
        "for trigram, count in trigram_counts.most_common(10):\n",
        "    print(f\"{trigram}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN3qkhQnHNv-"
      },
      "outputs": [],
      "source": [
        "# import gensim.corpora as corpora\n",
        "# # Create Dictionary\n",
        "# id2word = corpora.Dictionary(high_pos_df['trigram_tokens'].tolist())\n",
        "\n",
        "# ## pruning\n",
        "# #id2word.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "# #    (Optional) Re-map the remaining token IDs to remove gaps\n",
        "# #id2word.compactify()\n",
        "\n",
        "# # 2. Convert each document to a Bag-of-Words\n",
        "# texts = high_pos_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # Term Document Frequency\n",
        "# corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "# # View\n",
        "# print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt9bnXIpIZJG"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models.ldamodel import LdaModel\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# import nltk\n",
        "# ## Build the basic LDA model\n",
        "# lda_model = LdaModel(corpus=corpus,\n",
        "#                                        id2word=id2word,\n",
        "#                                        num_topics=4,\n",
        "#                                        random_state=100,\n",
        "#                                        chunksize=250,\n",
        "#                                        passes=200,\n",
        "#                                         iterations= 100,\n",
        "#                                        alpha='auto',\n",
        "#                                       eta='auto',\n",
        "#                                        per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xHfYsxAIxUH"
      },
      "outputs": [],
      "source": [
        "# from pprint import pprint\n",
        "\n",
        "# # Print the Keyword in the 3 topics\n",
        "# pprint(lda_model.print_topics())\n",
        "# doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Hv9oB1I2Gn"
      },
      "outputs": [],
      "source": [
        "# from gensim.models import CoherenceModel\n",
        "# #\n",
        "# # Compute Coherence Score\n",
        "# coherence_model_lda = CoherenceModel(model=lda_model, texts=high_pos_df['trigram_tokenized'], dictionary=id2word, coherence='c_v')\n",
        "# coherence_lda = coherence_model_lda.get_coherence()\n",
        "# print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etcfCqmmJoUl"
      },
      "outputs": [],
      "source": [
        "# import pyLDAvis.gensim\n",
        "# import pickle\n",
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim_models as gensimvis\n",
        "# import pyLDAvis\n",
        "\n",
        "# # Assuming ldamodel, corpus, and dictionary are already defined\n",
        "# # Enable the automatic display of visualizations in Jupyter\n",
        "# pyLDAvis.enable_notebook()\n",
        "\n",
        "# # Prepare the LDA visualization directly\n",
        "# LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "# # Display the prepared visualization directly in the notebook\n",
        "# pyLDAvis.display(LDAvis_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8xgFgGI18N_"
      },
      "outputs": [],
      "source": [
        "# # Extracting and printing the top 30 salient terms for each topic\n",
        "# num_topics = lda_model.num_topics\n",
        "# num_words = 30\n",
        "\n",
        "# for idx, topic in lda_model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False):\n",
        "#     print(f\"Topic {idx + 1}:\")\n",
        "#     for word, weight in topic:\n",
        "#         print(f\"  {word} ({weight:.4f})\")\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WRpMdF23X-E"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "texts = high_pos_df['trigram_tokens'].tolist()\n",
        "\n",
        "# Create a Dictionary and Corpus\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Function to compute coherence and perplexity\n",
        "def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations,seed):\n",
        "    lda_model = LdaModel(corpus=corpus,\n",
        "                         id2word=dictionary,\n",
        "                         num_topics=num_topics,\n",
        "                         random_state=seed,\n",
        "                         chunksize=chunksize,\n",
        "                         passes=passes,\n",
        "                         iterations=iterations,\n",
        "                         alpha='auto',\n",
        "                         eta='auto',\n",
        "                         per_word_topics=True)\n",
        "\n",
        "    perplexity = lda_model.log_perplexity(corpus)\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "     # Extract alpha and eta\n",
        "    alpha = lda_model.alpha\n",
        "    eta = lda_model.eta\n",
        "    return perplexity, coherence, alpha, eta\n",
        "\n",
        "# Define the parameter grid with your specific values\n",
        "seeds = [0, 1, 2]\n",
        "num_topics_range = range(2, 5)\n",
        "chunksize_range = [1000]\n",
        "passes_range = [100, 200,260]\n",
        "iterations_range = [50, 100, 200]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Grid search over all combinations of hyperparameters\n",
        "for seed in [0, 1, 2]:\n",
        "  for num_topics, chunksize, passes, iterations in itertools.product(num_topics_range, chunksize_range, passes_range, iterations_range):\n",
        "    perplexity, coherence, alpha, eta = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations, seed)\n",
        "    results.append((num_topics, chunksize, passes, iterations, perplexity, coherence, alpha, eta, seed))\n",
        "    # print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f}\"  f\"Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, \"\n",
        "      f\"Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f}, Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# Convert results to a DataFrame for better analysis\n",
        "results_df = pd.DataFrame(results, columns=['num_topics', 'chunksize', 'passes', 'iterations', 'perplexity', 'coherence','alpha','eta','seed'])\n",
        "# Add exponentiated perplexity column\n",
        "results_df['perplexity_exp'] = np.exp(-results_df['perplexity'])\n",
        "\n",
        "\n",
        "# Display results\n",
        "print(\"\\nResults:\")\n",
        "print(results_df)\n",
        "\n",
        "# Find the optimal number of topics with the highest coherence\n",
        "optimal_result = results_df.sort_values(\n",
        "    by=['coherence', 'perplexity_exp'],\n",
        "    ascending=[False, True]\n",
        ").iloc[0]\n",
        "optimal_num_topics = optimal_result['num_topics']\n",
        "optimal_chunksize = optimal_result['chunksize']\n",
        "optimal_passes = optimal_result['passes']\n",
        "optimal_iterations = optimal_result['iterations']\n",
        "optimal_perplexity = optimal_result['perplexity_exp']\n",
        "optimal_coherence = optimal_result['coherence']\n",
        "optimal_alpha = optimal_result['alpha']\n",
        "optimal_eta   = optimal_result['eta']\n",
        "optimal_seed = optimal_result['seed']\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\nOptimal Parameters:\")\n",
        "print(f\"Number of Topics: {optimal_num_topics}\")\n",
        "print(f\"Chunksize: {optimal_chunksize}\")\n",
        "print(f\"Passes: {optimal_passes}\")\n",
        "print(f\"Iterations: {optimal_iterations}\")\n",
        "print(f\"Coherence: {optimal_coherence:.4f}\")\n",
        "print(f\"Perplexity: {optimal_perplexity:.4f}\")\n",
        "print(f\" Alpha (per topic): {optimal_alpha}\")\n",
        "print(f\" Eta   (per word):  {optimal_eta}\")\n",
        "print(f\" seed:  {optimal_seed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzsWMTBAD87J"
      },
      "outputs": [],
      "source": [
        "# 1. Fit the model\n",
        "lda_opt = LdaModel(\n",
        "    corpus        = corpus,\n",
        "    id2word       = dictionary,\n",
        "    num_topics    = optimal_num_topics,\n",
        "    chunksize     = optimal_chunksize,\n",
        "    passes        = optimal_passes,\n",
        "    iterations    = optimal_iterations,\n",
        "    alpha         = 'auto',\n",
        "    eta           = 'auto',\n",
        "    random_state  = optimal_seed,\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "# 2. Extract metrics and priors\n",
        "opt_perp  = lda_opt.log_perplexity(corpus)\n",
        "opt_coh   = CoherenceModel(model=lda_opt, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
        "opt_alpha = lda_opt.alpha\n",
        "opt_eta   = lda_opt.eta\n",
        "\n",
        "print(f\"Re-fitted Optimal Model:\")\n",
        "print(f\" Coherence: {opt_coh:.4f}\")\n",
        "print(f\" Perplexity: {opt_perp:.4f}\")\n",
        "print(f\" Alpha (per topic): {opt_alpha}\")\n",
        "print(f\" Eta   (per word):  {opt_eta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ayc4j4Z4suf0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Grab your metrics & hyper‐params\n",
        "coherence_val  = opt_coh\n",
        "perplexity_val = opt_perp\n",
        "alpha_val      = opt_alpha\n",
        "eta_vals       = opt_eta  # full array\n",
        "\n",
        "# 2. Write them into a single text file\n",
        "with open('lda_model_full_summary_4th_mild_pos.txt', 'w') as f:\n",
        "    ...\n",
        "    f.write(\"Re-fitted Optimal Model:\\n\")\n",
        "    f.write(f\" Coherence:  {coherence_val:.4f}\\n\")\n",
        "    f.write(f\" Perplexity: {perplexity_val:.4f}\\n\")\n",
        "    f.write(f\" Alpha:      {alpha_val}\\n\")\n",
        "    f.write(\" Eta values:\\n\")\n",
        "    for eta in eta_vals:\n",
        "        f.write(f\"{eta}\\n\")\n",
        "\n",
        "\n",
        "files.download('lda_model_full_summary_4th_mild_pos.txt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeudiTLnEiAw"
      },
      "outputs": [],
      "source": [
        "# Cell 3: verify that the refit recovered the same priors\n",
        "import numpy as np\n",
        "\n",
        "print(\"Alpha match:\", np.allclose(optimal_alpha, opt_alpha))\n",
        "print(\"Eta   match:\", np.allclose(optimal_eta,   opt_eta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxdK7mI7n2AI"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "from pprint import pprint\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "\n",
        "# Cell 2: Print topics & sample document–topic distribution\n",
        "print(\"=== Topics ===\")\n",
        "pprint(lda_opt.print_topics())\n",
        "\n",
        "doc_topics = [lda_opt.get_document_topics(doc) for doc in corpus]\n",
        "print(\"\\nSample doc-topic distribution for doc 0:\")\n",
        "pprint(doc_topics[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCk_x4tCqxlH"
      },
      "outputs": [],
      "source": [
        "# Cell 3: pyLDAvis visualization\n",
        "# (make sure you’ve run `%matplotlib inline` or enabled notebook output)\n",
        "pyLDAvis.enable_notebook()\n",
        "vis_data = gensimvis.prepare(lda_opt, corpus, dictionary)\n",
        "pyLDAvis.display(vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8lMgF8Aq6U6"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Print the top 30 terms per topic\n",
        "print(\"\\n=== Top 30 terms per topic ===\")\n",
        "for topic_id, term_weights in lda_opt.show_topics(\n",
        "        num_topics=lda_opt.num_topics,\n",
        "        num_words=30,\n",
        "        formatted=False):\n",
        "    print(f\"Topic {topic_id + 1}:\")\n",
        "    for word, weight in term_weights:\n",
        "        print(f\"  {word} ({weight:.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdoxZTZ20Fi-"
      },
      "outputs": [],
      "source": [
        "# import gensim.corpora as corpora\n",
        "# # # Create Dictionary\n",
        "# id2word = corpora.Dictionary(high_pos_df['trigram_tokens'].tolist())\n",
        "\n",
        "# # ## pruning\n",
        "# id2word.filter_extremes(no_below=5, no_above=0.7)\n",
        "\n",
        "# # #    (Optional) Re-map the remaining token IDs to remove gaps\n",
        "# id2word.compactify()\n",
        "\n",
        "# # # 2. Convert each document to a Bag-of-Words\n",
        "# texts = high_pos_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # # Term Document Frequency\n",
        "# corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "# # # View\n",
        "# print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg7M93m60KF8"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models import LdaModel\n",
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import itertools\n",
        "\n",
        "\n",
        "# # Create a Dictionary and Corpus\n",
        "# dictionary = id2word\n",
        "\n",
        "\n",
        "# # Function to compute coherence and perplexity\n",
        "# def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations):\n",
        "#     lda_model = LdaModel(corpus=corpus,\n",
        "#                          id2word=dictionary,\n",
        "#                          num_topics=num_topics,\n",
        "#                          random_state=100,\n",
        "#                          chunksize=chunksize,\n",
        "#                          passes=passes,\n",
        "#                          iterations=iterations,\n",
        "#                          alpha='auto',\n",
        "#                          eta='auto',\n",
        "#                          per_word_topics=True)\n",
        "\n",
        "#     perplexity = lda_model.log_perplexity(corpus)\n",
        "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "#     coherence = coherence_model_lda.get_coherence()\n",
        "#      # Extract alpha and eta\n",
        "#     alpha = lda_model.alpha\n",
        "#     eta = lda_model.eta\n",
        "#     return perplexity, coherence, alpha, eta\n",
        "\n",
        "# # Define the parameter grid with your specific values\n",
        "# num_topics_range = range(2, 10)  # Adjust the range based on your needs\n",
        "# chunksize_range = [250]\n",
        "# passes_range = [100, 200,260]\n",
        "# iterations_range = [50, 100, 200]\n",
        "\n",
        "# # Store results\n",
        "# results = []\n",
        "\n",
        "# # Grid search over all combinations of hyperparameters\n",
        "# for num_topics, chunksize, passes, iterations in itertools.product(num_topics_range, chunksize_range, passes_range, iterations_range):\n",
        "#     perplexity, coherence, alpha, eta = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations)\n",
        "#     results.append((num_topics, chunksize, passes, iterations, perplexity, coherence, alpha, eta))\n",
        "#     # print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f}\"  f\"Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, \"\n",
        "#       f\"Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f}, Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# # Convert results to a DataFrame for better analysis\n",
        "# results_df = pd.DataFrame(results, columns=['num_topics', 'chunksize', 'passes', 'iterations', 'perplexity', 'coherence','alpha','eta'])\n",
        "# # Add exponentiated perplexity column\n",
        "# results_df['perplexity_exp'] = np.exp(-results_df['perplexity'])\n",
        "\n",
        "\n",
        "# # Display results\n",
        "# print(\"\\nResults:\")\n",
        "# print(results_df)\n",
        "\n",
        "# # Find the optimal number of topics with the highest coherence\n",
        "# optimal_result = results_df.sort_values(\n",
        "#     by=['coherence', 'perplexity_exp'],\n",
        "#     ascending=[False, True]\n",
        "# ).iloc[0]\n",
        "# optimal_num_topics = optimal_result['num_topics']\n",
        "# optimal_chunksize = optimal_result['chunksize']\n",
        "# optimal_passes = optimal_result['passes']\n",
        "# optimal_iterations = optimal_result['iterations']\n",
        "# optimal_perplexity = optimal_result['perplexity_exp']\n",
        "# optimal_coherence = optimal_result['coherence']\n",
        "# optimal_alpha = optimal_result['alpha']\n",
        "# optimal_eta   = optimal_result['eta']\n",
        "\n",
        "\n",
        "# print(f\"\\nOptimal Parameters:\")\n",
        "# print(f\"Number of Topics: {optimal_num_topics}\")\n",
        "# print(f\"Chunksize: {optimal_chunksize}\")\n",
        "# print(f\"Passes: {optimal_passes}\")\n",
        "# print(f\"Iterations: {optimal_iterations}\")\n",
        "# print(f\"Coherence: {optimal_coherence:.4f}\")\n",
        "# print(f\"Perplexity: {optimal_perplexity:.4f}\")\n",
        "# print(f\" Alpha (per topic): {optimal_alpha}\")\n",
        "# print(f\" Eta   (per word):  {optimal_eta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6xlGOuk0fSH"
      },
      "outputs": [],
      "source": [
        "# # 1. Fit the model\n",
        "# lda_opt = LdaModel(\n",
        "#     corpus        = corpus,\n",
        "#     id2word       = dictionary,\n",
        "#     num_topics    = optimal_num_topics,\n",
        "#     chunksize     = optimal_chunksize,\n",
        "#     passes        = optimal_passes,\n",
        "#     iterations    = optimal_iterations,\n",
        "#     alpha         = 'auto',\n",
        "#     eta           = 'auto',\n",
        "#     random_state  = 100,\n",
        "#     per_word_topics=True\n",
        "# )\n",
        "\n",
        "# # 2. Extract metrics and priors\n",
        "# opt_perp  = lda_opt.log_perplexity(corpus)\n",
        "# opt_coh   = CoherenceModel(model=lda_opt, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
        "# opt_alpha = lda_opt.alpha\n",
        "# opt_eta   = lda_opt.eta\n",
        "\n",
        "# print(f\"Re-fitted Optimal Model:\")\n",
        "# print(f\" Coherence: {opt_coh:.4f}\")\n",
        "# print(f\" Perplexity: {opt_perp:.4f}\")\n",
        "# print(f\" Alpha (per topic): {opt_alpha}\")\n",
        "# print(f\" Eta   (per word):  {opt_eta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf9JtspW0km7"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from google.colab import files\n",
        "\n",
        "# # 1. Grab your metrics & hyper‐params\n",
        "# coherence_val  = opt_coh\n",
        "# perplexity_val = opt_perp\n",
        "# alpha_val      = opt_alpha\n",
        "# eta_vals       = opt_eta  # full array\n",
        "\n",
        "# # 2. Write them into a single text file\n",
        "# with open('lda_model_full_summary.txt', 'w') as f:\n",
        "#     f.write(\"Re-fitted Optimal Model:\\n\")\n",
        "#     f.write(f\" Coherence:  {coherence_val:.4f}\\n\")\n",
        "#     f.write(f\" Perplexity: {perplexity_val:.4f}\\n\")\n",
        "#     f.write(f\" Alpha:      {alpha_val}\\n\")\n",
        "#     f.write(\" Eta values:\\n\")\n",
        "#     for eta in eta_vals:\n",
        "#         f.write(f\"{eta}\\n\")\n",
        "\n",
        "# # 3. Trigger the download\n",
        "# files.download('lda_model_full_summary.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wh8BuUr0nbF"
      },
      "outputs": [],
      "source": [
        "# # Cell 3: verify that the refit recovered the same priors\n",
        "# import numpy as np\n",
        "\n",
        "# print(\"Alpha match:\", np.allclose(optimal_alpha, opt_alpha))\n",
        "# print(\"Eta   match:\", np.allclose(optimal_eta,   opt_eta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iJ0eaGy0qmZ"
      },
      "outputs": [],
      "source": [
        "# # Cell 1: Imports\n",
        "# from pprint import pprint\n",
        "# import pyLDAvis.gensim_models as gensimvis\n",
        "# import pyLDAvis\n",
        "\n",
        "# # Cell 2: Print topics & sample document–topic distribution\n",
        "# print(\"=== Topics ===\")\n",
        "# pprint(lda_opt.print_topics())\n",
        "\n",
        "# doc_topics = [lda_opt.get_document_topics(doc) for doc in corpus]\n",
        "# print(\"\\nSample doc-topic distribution for doc 0:\")\n",
        "# pprint(doc_topics[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEcrpKzx0uIg"
      },
      "outputs": [],
      "source": [
        "# # Cell 3: pyLDAvis visualization\n",
        "# # (make sure you’ve run `%matplotlib inline` or enabled notebook output)\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis_data = gensimvis.prepare(lda_opt, corpus, dictionary)\n",
        "# pyLDAvis.display(vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UZbC_IiS0xhT"
      },
      "outputs": [],
      "source": [
        "# # Cell 4: Print the top 30 terms per topic\n",
        "# print(\"\\n=== Top 30 terms per topic ===\")\n",
        "# for topic_id, term_weights in lda_opt.show_topics(\n",
        "#         num_topics=lda_opt.num_topics,\n",
        "#         num_words=30,\n",
        "#         formatted=False):\n",
        "#     print(f\"Topic {topic_id + 1}:\")\n",
        "#     for word, weight in term_weights:\n",
        "#         print(f\"  {word} ({weight:.4f})\")\n",
        "#     print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lTSpqyRRNeFB",
        "outputId": "2d750dd8-4e9f-478d-b90d-3c74f90a36b0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a5cd12c30f08>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m####### HIGH NEGATIVE FOR FIRST COVID WAVE ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Filter the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhigh_neg_first_wave_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mild neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert the 'created_utc' column to datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "####### HIGH NEGATIVE FOR FIRST COVID WAVE ########\n",
        "# Filter the DataFrame\n",
        "high_neg_first_wave_df = df[df['label'] == 'mild neg']\n",
        "\n",
        "# Convert the 'created_utc' column to datetime\n",
        "high_neg_first_wave_df['created_utc'] = pd.to_datetime(high_neg_first_wave_df['created_utc'])\n",
        "\n",
        "# Define your date range\n",
        "# start_date = '2020-01-01'\n",
        "# end_date = '2020-05-31'\n",
        "# Define your date range\n",
        "# start_date = '2020-10-01'\n",
        "# end_date = '2021-01-31'\n",
        "# start_date = '2021-11-01'\n",
        "# end_date = '2022-01-31'\n",
        "start_date = '2022-11-01'\n",
        "end_date = '2023-01-31'\n",
        "\n",
        "# Filter the DataFrame for entries within the specified date range\n",
        "high_neg_first_wave_df = high_neg_first_wave_df[(high_neg_first_wave_df['created_utc'] >= start_date) & (high_neg_first_wave_df['created_utc'] <= end_date)]\n",
        "\n",
        "\n",
        "# Print the filtered DataFrame to check the result\n",
        "high_neg_first_wave_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvuh8kxPZ8Yy"
      },
      "outputs": [],
      "source": [
        "high_neg_first_wave_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1OTWZNQaXj8"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Flatten your tokens into one long list\n",
        "all_tokens = [t for toks in high_neg_first_wave_df['tokens'] for t in toks]\n",
        "\n",
        "# 2) Build a frequency distribution\n",
        "freq = Counter(all_tokens)\n",
        "common = freq.most_common(30)   # top 30\n",
        "\n",
        "# 3) Turn it into a DataFrame for easy inspection\n",
        "df_freq = pd.DataFrame(common, columns=['token','count'])\n",
        "print(df_freq)\n",
        "\n",
        "# 4) Plot a simple bar chart of the top tokens\n",
        "tokens, counts = zip(*common)\n",
        "plt.figure()\n",
        "plt.bar(tokens, counts)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Token')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 30 Tokens in high_negative_df')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btQD7R99all4"
      },
      "outputs": [],
      "source": [
        "# Flatten all tokens into one list\n",
        "all_words   = [word for tokens in high_neg_first_wave_df['tokens'] for word in tokens]\n",
        "\n",
        "# Compute the length (in tokens) of each post\n",
        "post_length = [len(tokens) for tokens in high_neg_first_wave_df['tokens']]\n",
        "\n",
        "# Build the vocabulary\n",
        "vocab       = sorted(set(all_words))\n",
        "\n",
        "# Print your summary stats\n",
        "print(f\"{len(all_words)} words total, with a vocabulary size of {len(vocab)}\")\n",
        "print(f\"Max reddit post length is {max(post_length)} tokens\")\n",
        "print(f\"Mean reddit post length is {sum(post_length)/len(post_length):.2f} tokens\")\n",
        "print(f\"Median reddit post length is {sorted(post_length)[len(post_length)//2]} tokens\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rve3QhCUau2i"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "sns.histplot(post_length, bins=60, kde=True)\n",
        "plt.title('Post Length Distribution', fontsize=18)\n",
        "plt.xlabel('Words per Post', fontsize=12)\n",
        "plt.ylabel('Number of Posts', fontsize=12)\n",
        "# Setting x-axis ticks and labels for more detail\n",
        "max_length = max(post_length)\n",
        "xticks = np.arange(0, max_length + 1, max_length // 60)  # Adjust the step size as needed\n",
        "plt.xticks(xticks)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrkzaktPa0tn"
      },
      "outputs": [],
      "source": [
        "#!pip install  gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFMsom6Fb4XP"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "# 1) Prepare your list-of-lists from the `tokens` column\n",
        "texts = high_neg_first_wave_df['tokens'].tolist()\n",
        "\n",
        "# 2) Train the bigram detector\n",
        "bigram = Phrases(texts, min_count=3, threshold=60)\n",
        "bigram_mod = Phraser(bigram)\n",
        "\n",
        "# 3) Train the trigram detector on the bigram-transformed texts\n",
        "trigram = Phrases(bigram[texts], min_count=2, threshold=150)\n",
        "trigram_mod = Phraser(trigram)\n",
        "\n",
        "# 4) Apply bigram and trigram transforms\n",
        "high_neg_first_wave_df['bigram_tokens']   = high_neg_first_wave_df['tokens'].apply(lambda doc: bigram_mod[doc])\n",
        "high_neg_first_wave_df['trigram_tokens']  = high_neg_first_wave_df['tokens'].apply(lambda doc: trigram_mod[bigram_mod[doc]])\n",
        "\n",
        "# # 5) (Optional) If you need back a single string for vectorizers:\n",
        "# high_neg_first_wave_df['bigram_text']   = high_neg_first_wave_df['bigram_tokens'].str.join(' ')\n",
        "# high_neg_first_wave_df['trigram_text']  = high_neg_first_wave_df['trigram_tokens'].str.join(' ')\n",
        "\n",
        "# 6) Inspect\n",
        "print(high_neg_first_wave_df[['tokens','bigram_tokens','trigram_tokens']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLMqGnXScCM7"
      },
      "outputs": [],
      "source": [
        "# 1) Helper to detect n-grams in a token list\n",
        "def contains_ngram(tokenized_list, n):\n",
        "    return any(len(tok.split('_')) == n for tok in tokenized_list)\n",
        "\n",
        "# 2) Flag rows\n",
        "high_neg_first_wave_df['has_bigrams']  = high_neg_first_wave_df['bigram_tokens'].apply(lambda doc: contains_ngram(doc, 2))\n",
        "high_neg_first_wave_df['has_trigrams'] = high_neg_first_wave_df['trigram_tokens'].apply(lambda doc: contains_ngram(doc, 3))\n",
        "\n",
        "# 3) Count\n",
        "rows_with_bigrams  = high_neg_first_wave_df['has_bigrams'].sum()\n",
        "rows_with_trigrams = high_neg_first_wave_df['has_trigrams'].sum()\n",
        "rows_with_none     = (~high_neg_first_wave_df['has_bigrams'] & ~high_neg_first_wave_df['has_trigrams']).sum()\n",
        "\n",
        "# 4) Report\n",
        "print(f\"Rows with bigrams:   {rows_with_bigrams}\")\n",
        "print(f\"Rows with trigrams:  {rows_with_trigrams}\")\n",
        "print(f\"Rows with no n-grams: {rows_with_none}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKHQtNgCcIDm"
      },
      "outputs": [],
      "source": [
        "high_neg_first_wave_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ATF-4cSpcKxG",
        "outputId": "18578d6e-a558-4661-e94e-956db3bb8e80"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'high_neg_first_wave_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2885d3d07135>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the total number of rows in the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhigh_neg_first_wave_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total number of rows in the DataFrame: {total_rows}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check the number of rows in the 'trigram_tokenized' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'high_neg_first_wave_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Print the total number of rows in the DataFrame\n",
        "total_rows = high_neg_first_wave_df.shape[0]\n",
        "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
        "\n",
        "# Check the number of rows in the 'trigram_tokenized' column\n",
        "print(f\"Number of rows in 'trigram_tokenized' column: {high_neg_first_wave_df['trigram_tokens'].shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJypHxwXcPN2"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# 1) Flatten all trigram lists into one big sequence\n",
        "all_trigrams = itertools.chain.from_iterable(high_neg_first_wave_df['trigram_tokens'])\n",
        "\n",
        "# 2) Filter for genuine trigrams (exactly two underscores → three words joined)\n",
        "trigram_counts = Counter(\n",
        "    token for token in all_trigrams\n",
        "    if isinstance(token, str) and token.count('_') == 2\n",
        ")\n",
        "\n",
        "# 3) How many unique trigrams?\n",
        "total_unique_trigrams = len(trigram_counts)\n",
        "print(f\"Total number of unique trigrams: {total_unique_trigrams}\")\n",
        "\n",
        "# 4) Show the 10 most common trigrams\n",
        "print(\"\\nMost common trigrams:\")\n",
        "for trigram, count in trigram_counts.most_common(10):\n",
        "    print(f\"{trigram}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1NHF9x_bYzm"
      },
      "outputs": [],
      "source": [
        "# import gensim.corpora as corpora\n",
        "# # Create Dictionary\n",
        "# id2word = corpora.Dictionary(high_neg_first_wave_df['trigram_tokens'].tolist())\n",
        "\n",
        "# ## pruning\n",
        "# #id2word.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "# #    (Optional) Re-map the remaining token IDs to remove gaps\n",
        "# #id2word.compactify()\n",
        "\n",
        "# # 2. Convert each document to a Bag-of-Words\n",
        "# texts = high_neg_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # Term Document Frequency\n",
        "# corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "# # View\n",
        "# print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3zzk3UlbrCu"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models.ldamodel import LdaModel\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# import nltk\n",
        "# ## Build the basic LDA model\n",
        "# lda_model = LdaModel(corpus=corpus,\n",
        "#                                        id2word=id2word,\n",
        "#                                        num_topics=2,\n",
        "#                                        random_state=100,\n",
        "#                                           chunksize=250,\n",
        "#                                        passes=100,\n",
        "#                                         iterations= 200,\n",
        "#                                        alpha='auto',\n",
        "#                                       eta='auto',\n",
        "#                                        per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFZIK0RZbznf"
      },
      "outputs": [],
      "source": [
        "# from pprint import pprint\n",
        "\n",
        "# # Print the Keyword in the 3 topics\n",
        "# pprint(lda_model.print_topics())\n",
        "# doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezfm299-cSZE"
      },
      "outputs": [],
      "source": [
        "# import pyLDAvis.gensim\n",
        "# import pickle\n",
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim_models as gensimvis\n",
        "# import pyLDAvis\n",
        "\n",
        "# # Assuming ldamodel, corpus, and dictionary are already defined\n",
        "# # Enable the automatic display of visualizations in Jupyter\n",
        "# pyLDAvis.enable_notebook()\n",
        "\n",
        "# # Prepare the LDA visualization directly\n",
        "# LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "# # Display the prepared visualization directly in the notebook\n",
        "# pyLDAvis.display(LDAvis_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHJIO3s3cldR"
      },
      "outputs": [],
      "source": [
        "# # Extracting and printing the top 30 salient terms for each topic\n",
        "# num_topics = lda_model.num_topics\n",
        "# num_words = 30\n",
        "\n",
        "# for idx, topic in lda_model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False):\n",
        "#     print(f\"Topic {idx + 1}:\")\n",
        "#     for word, weight in topic:\n",
        "#         print(f\"  {word} ({weight:.4f})\")\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOWbF0k0cZXT"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Assuming high_pos_df['trigram_tokenized'] contains lists of lemmatized trigram tokens\n",
        "texts = high_neg_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# Create a Dictionary and Corpus\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Function to compute coherence and perplexity\n",
        "def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations, seed):\n",
        "    lda_model = LdaModel(corpus=corpus,\n",
        "                         id2word=dictionary,\n",
        "                         num_topics=num_topics,\n",
        "                         random_state=seed,\n",
        "                         chunksize=chunksize,\n",
        "                         passes=passes,\n",
        "                         iterations=iterations,\n",
        "                         alpha='auto',\n",
        "                         eta='auto',\n",
        "                         per_word_topics=True)\n",
        "\n",
        "    perplexity = lda_model.log_perplexity(corpus)\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "     # Extract alpha and eta\n",
        "    alpha = lda_model.alpha\n",
        "    eta = lda_model.eta\n",
        "    return perplexity, coherence, alpha, eta\n",
        "\n",
        "# Define the parameter grid with your specific values\n",
        "num_topics_range = range(2, 10)  # Adjust the range based on your needs\n",
        "chunksize_range = [300]\n",
        "passes_range = [100, 200,260]\n",
        "iterations_range = [50,100, 200]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Grid search over all combinations of hyperparameters\n",
        "for seed in [0, 1, 2]:\n",
        "  for num_topics, chunksize, passes, iterations in itertools.product(num_topics_range, chunksize_range, passes_range, iterations_range):\n",
        "    perplexity, coherence , alpha, eta = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations, seed)\n",
        "    results.append((num_topics, chunksize, passes, iterations, perplexity, coherence,alpha,eta, seed))\n",
        "    print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f}, Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# Convert results to a DataFrame for better analysis\n",
        "results_df = pd.DataFrame(results, columns=['num_topics', 'chunksize', 'passes', 'iterations', 'perplexity', 'coherence','alpha','eta','seed'])\n",
        "\n",
        "# Add exponentiated perplexity column\n",
        "results_df['perplexity_exp'] = np.exp(-results_df['perplexity'])\n",
        "\n",
        "# Display results\n",
        "print(\"\\nResults:\")\n",
        "print(results_df)\n",
        "\n",
        "# Find the optimal number of topics with the highest coherence\n",
        "optimal_result = results_df.sort_values(\n",
        "    by=['coherence', 'perplexity_exp'],\n",
        "    ascending=[False, True]\n",
        ").iloc[0]\n",
        "optimal_num_topics = optimal_result['num_topics']\n",
        "optimal_chunksize = optimal_result['chunksize']\n",
        "optimal_passes = optimal_result['passes']\n",
        "optimal_iterations = optimal_result['iterations']\n",
        "optimal_perplexity = optimal_result['perplexity_exp']\n",
        "optimal_coherence = optimal_result['coherence']\n",
        "optimal_alpha = optimal_result['alpha']\n",
        "optimal_eta   = optimal_result['eta']\n",
        "optimal_seed = optimal_result['seed']\n",
        "\n",
        "print(f\"\\nOptimal Parameters:\")\n",
        "print(f\"Number of Topics: {optimal_num_topics}\")\n",
        "print(f\"Chunksize: {optimal_chunksize}\")\n",
        "print(f\"Passes: {optimal_passes}\")\n",
        "print(f\"Iterations: {optimal_iterations}\")\n",
        "print(f\"Coherence: {optimal_coherence:.4f}\")\n",
        "print(f\"Perplexity: {optimal_perplexity:.4f}\")\n",
        "print(f\" Alpha (per topic): {optimal_alpha}\")\n",
        "print(f\" Eta   (per word):  {optimal_eta}\")\n",
        "print(f\" seed:  {optimal_seed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MRNtYBBcvN4G",
        "outputId": "243f510e-ce5a-4910-f015-15a1f739c6b2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LdaModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-24e201c615f9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m lda_opt = LdaModel(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcorpus\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mid2word\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_topics\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0moptimal_num_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LdaModel' is not defined"
          ]
        }
      ],
      "source": [
        "# 1. Fit the model\n",
        "lda_opt = LdaModel(\n",
        "    corpus        = corpus,\n",
        "    id2word       = dictionary,\n",
        "    num_topics    = optimal_num_topics,\n",
        "    chunksize     = optimal_chunksize,\n",
        "    passes        = optimal_passes,\n",
        "    iterations    = optimal_iterations,\n",
        "    alpha         = 'auto',\n",
        "    eta           = 'auto',\n",
        "    random_state  = optimal_seed,\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "# 2. Extract metrics and priors\n",
        "opt_perp  = lda_opt.log_perplexity(corpus)\n",
        "opt_coh   = CoherenceModel(model=lda_opt, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
        "opt_alpha = lda_opt.alpha\n",
        "opt_eta   = lda_opt.eta\n",
        "\n",
        "print(f\"Re-fitted Optimal Model:\")\n",
        "print(f\" Coherence: {opt_coh:.4f}\")\n",
        "print(f\" Perplexity: {opt_perp:.4f}\")\n",
        "print(f\" Alpha (per topic): {opt_alpha}\")\n",
        "print(f\" Eta   (per word):  {opt_eta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SK9KveRnu-Su",
        "outputId": "0d573412-2448-442d-ef6a-5c2aaed1df11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'opt_coh' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-de31eca1a94c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1. Grab your metrics & hyper‐params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcoherence_val\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mopt_coh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mperplexity_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_perp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0malpha_val\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mopt_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opt_coh' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Grab your metrics & hyper‐params\n",
        "coherence_val  = opt_coh\n",
        "perplexity_val = opt_perp\n",
        "alpha_val      = opt_alpha\n",
        "eta_vals       = opt_eta  # full array\n",
        "\n",
        "# 2. Write them into a single text file\n",
        "with open('lda_model_full_summary_4th_mild_neg.txt', 'w') as f:\n",
        "    f.write(\"Re-fitted Optimal Model:\\n\")\n",
        "    f.write(f\" Coherence:  {coherence_val:.4f}\\n\")\n",
        "    f.write(f\" Perplexity: {perplexity_val:.4f}\\n\")\n",
        "    f.write(f\" Alpha:      {alpha_val}\\n\")\n",
        "    f.write(\" Eta values:\\n\")\n",
        "    for eta in eta_vals:\n",
        "        f.write(f\"{eta}\\n\")\n",
        "    f.flush()  # Ensure it's written to disk\n",
        "# 3. Trigger the download\n",
        "files.download('lda_model_full_summary_4th_mild_neg.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbA-Oc5NvCxI"
      },
      "outputs": [],
      "source": [
        "# Cell 3: verify that the refit recovered the same priors\n",
        "import numpy as np\n",
        "\n",
        "print(\"Alpha match:\", np.allclose(optimal_alpha, opt_alpha))\n",
        "print(\"Eta   match:\", np.allclose(optimal_eta,   opt_eta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H8vcUgrvER-"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "from pprint import pprint\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "\n",
        "# Cell 2: Print topics & sample document–topic distribution\n",
        "print(\"=== Topics ===\")\n",
        "pprint(lda_opt.print_topics())\n",
        "\n",
        "doc_topics = [lda_opt.get_document_topics(doc) for doc in corpus]\n",
        "print(\"\\nSample doc-topic distribution for doc 0:\")\n",
        "pprint(doc_topics[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeDK0p3evF2J"
      },
      "outputs": [],
      "source": [
        "# Cell 3: pyLDAvis visualization\n",
        "# (make sure you’ve run `%matplotlib inline` or enabled notebook output)\n",
        "pyLDAvis.enable_notebook()\n",
        "vis_data = gensimvis.prepare(lda_opt, corpus, dictionary)\n",
        "pyLDAvis.display(vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lqX2mikvHhy"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Print the top 30 terms per topic\n",
        "print(\"\\n=== Top 30 terms per topic ===\")\n",
        "for topic_id, term_weights in lda_opt.show_topics(\n",
        "        num_topics=lda_opt.num_topics,\n",
        "        num_words=30,\n",
        "        formatted=False):\n",
        "    print(f\"Topic {topic_id + 1}:\")\n",
        "    for word, weight in term_weights:\n",
        "        print(f\"  {word} ({weight:.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ukQLkeK6u8D7"
      },
      "outputs": [],
      "source": [
        "# import gensim.corpora as corpora\n",
        "# # Create Dictionary\n",
        "# id2word = corpora.Dictionary(high_neg_first_wave_df['trigram_tokens'].tolist())\n",
        "\n",
        "# ## pruning\n",
        "# id2word.filter_extremes(no_below=5, no_above=0.7)\n",
        "\n",
        "# #    (Optional) Re-map the remaining token IDs to remove gaps\n",
        "# id2word.compactify()\n",
        "\n",
        "# # 2. Convert each document to a Bag-of-Words\n",
        "# texts = high_neg_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # Term Document Frequency\n",
        "# corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "# # View\n",
        "# print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bd-FL1UB1HE9"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models import LdaModel\n",
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import itertools\n",
        "\n",
        "\n",
        "# # Create a Dictionary and Corpus\n",
        "# dictionary = id2word\n",
        "\n",
        "\n",
        "# # Function to compute coherence and perplexity\n",
        "# def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations):\n",
        "#     lda_model = LdaModel(corpus=corpus,\n",
        "#                          id2word=dictionary,\n",
        "#                          num_topics=num_topics,\n",
        "#                          random_state=100,\n",
        "#                          chunksize=chunksize,\n",
        "#                          passes=passes,\n",
        "#                          iterations=iterations,\n",
        "#                          alpha='auto',\n",
        "#                          eta='auto',\n",
        "#                          per_word_topics=True)\n",
        "\n",
        "#     perplexity = lda_model.log_perplexity(corpus)\n",
        "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "#     coherence = coherence_model_lda.get_coherence()\n",
        "#      # Extract alpha and eta\n",
        "#     alpha = lda_model.alpha\n",
        "#     eta = lda_model.eta\n",
        "#     return perplexity, coherence, alpha, eta\n",
        "\n",
        "# # Define the parameter grid with your specific values\n",
        "# num_topics_range = range(2, 10)  # Adjust the range based on your needs\n",
        "# chunksize_range = [250]\n",
        "# passes_range = [100, 200,260]\n",
        "# iterations_range = [50,100, 200]\n",
        "\n",
        "# # Store results\n",
        "# results = []\n",
        "\n",
        "# # Grid search over all combinations of hyperparameters\n",
        "# for num_topics, chunksize, passes, iterations in itertools.product(num_topics_range, chunksize_range, passes_range, iterations_range):\n",
        "#     perplexity, coherence , alpha, eta = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations)\n",
        "#     results.append((num_topics, chunksize, passes, iterations, perplexity, coherence,alpha,eta))\n",
        "#     print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f}, Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# # Convert results to a DataFrame for better analysis\n",
        "# results_df = pd.DataFrame(results, columns=['num_topics', 'chunksize', 'passes', 'iterations', 'perplexity', 'coherence','alpha','eta'])\n",
        "\n",
        "# # Add exponentiated perplexity column\n",
        "# results_df['perplexity_exp'] = np.exp(-results_df['perplexity'])\n",
        "\n",
        "# # Display results\n",
        "# print(\"\\nResults:\")\n",
        "# print(results_df)\n",
        "\n",
        "# # Find the optimal number of topics with the highest coherence\n",
        "# optimal_result = results_df.sort_values(\n",
        "#     by=['coherence', 'perplexity_exp'],\n",
        "#     ascending=[False, True]\n",
        "# ).iloc[0]\n",
        "# optimal_num_topics = optimal_result['num_topics']\n",
        "# optimal_chunksize = optimal_result['chunksize']\n",
        "# optimal_passes = optimal_result['passes']\n",
        "# optimal_iterations = optimal_result['iterations']\n",
        "# optimal_perplexity = optimal_result['perplexity_exp']\n",
        "# optimal_coherence = optimal_result['coherence']\n",
        "# optimal_alpha = optimal_result['alpha']\n",
        "# optimal_eta   = optimal_result['eta']\n",
        "\n",
        "# print(f\"\\nOptimal Parameters:\")\n",
        "# print(f\"Number of Topics: {optimal_num_topics}\")\n",
        "# print(f\"Chunksize: {optimal_chunksize}\")\n",
        "# print(f\"Passes: {optimal_passes}\")\n",
        "# print(f\"Iterations: {optimal_iterations}\")\n",
        "# print(f\"Coherence: {optimal_coherence:.4f}\")\n",
        "# print(f\"Perplexity: {optimal_perplexity:.4f}\")\n",
        "# print(f\" Alpha (per topic): {optimal_alpha}\")\n",
        "# print(f\" Eta   (per word):  {optimal_eta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k_-_UlAp1Vsy"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from google.colab import files\n",
        "\n",
        "# # 1. Grab your metrics & hyper‐params\n",
        "# coherence_val  = opt_coh\n",
        "# perplexity_val = opt_perp\n",
        "# alpha_val      = opt_alpha\n",
        "# eta_vals       = opt_eta  # full array\n",
        "\n",
        "# # 2. Write them into a single text file\n",
        "# with open('lda_model_full_summary.txt', 'w') as f:\n",
        "#     f.write(\"Re-fitted Optimal Model:\\n\")\n",
        "#     f.write(f\" Coherence:  {coherence_val:.4f}\\n\")\n",
        "#     f.write(f\" Perplexity: {perplexity_val:.4f}\\n\")\n",
        "#     f.write(f\" Alpha:      {alpha_val}\\n\")\n",
        "#     f.write(\" Eta values:\\n\")\n",
        "#     for eta in eta_vals:\n",
        "#         f.write(f\"{eta}\\n\")\n",
        "\n",
        "# # 3. Trigger the download\n",
        "# files.download('lda_model_full_summary.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RNl3Uwjn1OGX"
      },
      "outputs": [],
      "source": [
        "# # 1. Fit the model\n",
        "# lda_opt = LdaModel(\n",
        "#     corpus        = corpus,\n",
        "#     id2word       = dictionary,\n",
        "#     num_topics    = optimal_num_topics,\n",
        "#     chunksize     = optimal_chunksize,\n",
        "#     passes        = optimal_passes,\n",
        "#     iterations    = optimal_iterations,\n",
        "#     alpha         = 'auto',\n",
        "#     eta           = 'auto',\n",
        "#     random_state  = 100,\n",
        "#     per_word_topics=True\n",
        "# )\n",
        "\n",
        "# # 2. Extract metrics and priors\n",
        "# opt_perp  = lda_opt.log_perplexity(corpus)\n",
        "# opt_coh   = CoherenceModel(model=lda_opt, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
        "# opt_alpha = lda_opt.alpha\n",
        "# opt_eta   = lda_opt.eta\n",
        "\n",
        "# print(f\"Re-fitted Optimal Model:\")\n",
        "# print(f\" Coherence: {opt_coh:.4f}\")\n",
        "# print(f\" Perplexity: {opt_perp:.4f}\")\n",
        "# print(f\" Alpha (per topic): {opt_alpha}\")\n",
        "# print(f\" Eta   (per word):  {opt_eta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9A5V9QEA1ZWz"
      },
      "outputs": [],
      "source": [
        "# # Cell 3: verify that the refit recovered the same priors\n",
        "# import numpy as np\n",
        "\n",
        "# print(\"Alpha match:\", np.allclose(optimal_alpha, opt_alpha))\n",
        "# print(\"Eta   match:\", np.allclose(optimal_eta,   opt_eta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GoSfR4v51c1M"
      },
      "outputs": [],
      "source": [
        "# # Cell 1: Imports\n",
        "# from pprint import pprint\n",
        "# import pyLDAvis.gensim_models as gensimvis\n",
        "# import pyLDAvis\n",
        "\n",
        "# # Cell 2: Print topics & sample document–topic distribution\n",
        "# print(\"=== Topics ===\")\n",
        "# pprint(lda_opt.print_topics())\n",
        "\n",
        "# doc_topics = [lda_opt.get_document_topics(doc) for doc in corpus]\n",
        "# print(\"\\nSample doc-topic distribution for doc 0:\")\n",
        "# pprint(doc_topics[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_zwhNJRD1gGl"
      },
      "outputs": [],
      "source": [
        "# # Cell 3: pyLDAvis visualization\n",
        "# # (make sure you’ve run `%matplotlib inline` or enabled notebook output)\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis_data = gensimvis.prepare(lda_opt, corpus, dictionary)\n",
        "# pyLDAvis.display(vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4l9OIY-I1jDN"
      },
      "outputs": [],
      "source": [
        "# # Cell 4: Print the top 30 terms per topic\n",
        "# print(\"\\n=== Top 30 terms per topic ===\")\n",
        "# for topic_id, term_weights in lda_opt.show_topics(\n",
        "#         num_topics=lda_opt.num_topics,\n",
        "#         num_words=30,\n",
        "#         formatted=False):\n",
        "#     print(f\"Topic {topic_id + 1}:\")\n",
        "#     for word, weight in term_weights:\n",
        "#         print(f\"  {word} ({weight:.4f})\")\n",
        "#     print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Om8c7ENQCsFX",
        "outputId": "3f2d9137-6f90-4be8-94fb-8beacf827268"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b2111c4ccf98>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m####### HIGH neutral FOR FIRST COVID WAVE ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Filter the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhigh_neu_first_wave_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mild neu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert the 'created_utc' column to datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "####### HIGH neutral FOR FIRST COVID WAVE ########\n",
        "# Filter the DataFrame\n",
        "high_neu_first_wave_df = df[df['label'] == 'mild neu']\n",
        "\n",
        "# Convert the 'created_utc' column to datetime\n",
        "high_neu_first_wave_df['created_utc'] = pd.to_datetime(high_neu_first_wave_df['created_utc'])\n",
        "\n",
        "# Define your date range\n",
        "# start_date = '2020-01-01'\n",
        "# end_date = '2020-05-31'\n",
        "# Define your date range\n",
        "# start_date = '2020-10-01'\n",
        "# end_date = '2021-01-31'\n",
        "# start_date = '2021-11-01'\n",
        "# end_date = '2022-01-31'\n",
        "\n",
        "start_date = '2022-11-01'\n",
        "end_date = '2023-01-31'\n",
        "\n",
        "# Filter the DataFrame for entries within the specified date range\n",
        "high_neu_first_wave_df = high_neu_first_wave_df[(high_neu_first_wave_df['created_utc'] >= start_date) & (high_neu_first_wave_df['created_utc'] <= end_date)]\n",
        "\n",
        "\n",
        "# Print the filtered DataFrame to check the result\n",
        "high_neu_first_wave_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuocvL5jeYcJ"
      },
      "outputs": [],
      "source": [
        "high_neu_first_wave_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPT_Aq1Peii6"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Flatten your tokens into one long list\n",
        "all_tokens = [t for toks in high_neu_first_wave_df['tokens'] for t in toks]\n",
        "\n",
        "# 2) Build a frequency distribution\n",
        "freq = Counter(all_tokens)\n",
        "common = freq.most_common(30)   # top 30\n",
        "\n",
        "# 3) Turn it into a DataFrame for easy inspection\n",
        "df_freq = pd.DataFrame(common, columns=['token','count'])\n",
        "print(df_freq)\n",
        "\n",
        "# 4) Plot a simple bar chart of the top tokens\n",
        "tokens, counts = zip(*common)\n",
        "plt.figure()\n",
        "plt.bar(tokens, counts)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Token')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 30 Tokens in high_neu_first_wave_df')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DxUcpAFerdM"
      },
      "outputs": [],
      "source": [
        "# Flatten all tokens into one list\n",
        "all_words   = [word for tokens in high_neu_first_wave_df['tokens'] for word in tokens]\n",
        "\n",
        "# Compute the length (in tokens) of each post\n",
        "post_length = [len(tokens) for tokens in high_neu_first_wave_df['tokens']]\n",
        "\n",
        "# Build the vocabulary\n",
        "vocab       = sorted(set(all_words))\n",
        "\n",
        "# Print your summary stats\n",
        "print(f\"{len(all_words)} words total, with a vocabulary size of {len(vocab)}\")\n",
        "print(f\"Max reddit post length is {max(post_length)} tokens\")\n",
        "print(f\"Mean reddit post length is {sum(post_length)/len(post_length):.2f} tokens\")\n",
        "print(f\"Median reddit post length is {sorted(post_length)[len(post_length)//2]} tokens\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKB-6zSwe2C1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "sns.histplot(post_length, bins=60, kde=True)\n",
        "plt.title('Post Length Distribution', fontsize=18)\n",
        "plt.xlabel('Words per Post', fontsize=12)\n",
        "plt.ylabel('Number of Posts', fontsize=12)\n",
        "# Setting x-axis ticks and labels for more detail\n",
        "max_length = max(post_length)\n",
        "xticks = np.arange(0, max_length + 1, max_length // 60)  # Adjust the step size as needed\n",
        "plt.xticks(xticks)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-eN3u-cndFo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "sns.histplot(post_length, bins=60, kde=True)\n",
        "plt.title('Post Length Distribution', fontsize=18)\n",
        "plt.xlabel('Words per Post', fontsize=12)\n",
        "plt.ylabel('Number of Posts', fontsize=12)\n",
        "# Setting x-axis ticks and labels for more detail\n",
        "max_length = max(post_length)\n",
        "xticks = np.arange(0, max_length + 1, max_length // 60)  # Adjust the step size as needed\n",
        "plt.xticks(xticks)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A1SjV6hfDrI"
      },
      "outputs": [],
      "source": [
        "!pip install  gensim\n",
        "\n",
        "# #1) Downgrade NumPy to 1.26.x\n",
        "# !pip install numpy==1.26.0 --upgrade\n",
        "\n",
        "# # 2) Force-reinstall Gensim so it compiles against the new NumPy\n",
        "# !pip install --upgrade --force-reinstall gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MSg17RifUo6"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "# 1) Prepare your list-of-lists from the `tokens` column\n",
        "texts = high_neu_first_wave_df['tokens'].tolist()\n",
        "\n",
        "# 2) Train the bigram detector\n",
        "bigram = Phrases(texts, min_count=3, threshold=60)\n",
        "bigram_mod = Phraser(bigram)\n",
        "\n",
        "# 3) Train the trigram detector on the bigram-transformed texts\n",
        "trigram = Phrases(bigram[texts], min_count=2, threshold=150)\n",
        "trigram_mod = Phraser(trigram)\n",
        "\n",
        "# 4) Apply bigram and trigram transforms\n",
        "high_neu_first_wave_df['bigram_tokens']   = high_neu_first_wave_df['tokens'].apply(lambda doc: bigram_mod[doc])\n",
        "high_neu_first_wave_df['trigram_tokens']  = high_neu_first_wave_df['tokens'].apply(lambda doc: trigram_mod[bigram_mod[doc]])\n",
        "\n",
        "# # 5) (Optional) If you need back a single string for vectorizers:\n",
        "# high_neu_first_wave_df['bigram_text']   = high_neu_first_wave_df['bigram_tokens'].str.join(' ')\n",
        "# high_neu_first_wave_df['trigram_text']  = high_neu_first_wave_df['trigram_tokens'].str.join(' ')\n",
        "\n",
        "# 6) Inspect\n",
        "print(high_neu_first_wave_df[['tokens','bigram_tokens','trigram_tokens']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOnEAqb7fdsv"
      },
      "outputs": [],
      "source": [
        "# 1) Helper to detect n-grams in a token list\n",
        "def contains_ngram(tokenized_list, n):\n",
        "    return any(len(tok.split('_')) == n for tok in tokenized_list)\n",
        "\n",
        "# 2) Flag rows\n",
        "high_neu_first_wave_df['has_bigrams']  = high_neu_first_wave_df['bigram_tokens'].apply(lambda doc: contains_ngram(doc, 2))\n",
        "high_neu_first_wave_df['has_trigrams'] = high_neu_first_wave_df['trigram_tokens'].apply(lambda doc: contains_ngram(doc, 3))\n",
        "\n",
        "# 3) Count\n",
        "rows_with_bigrams  = high_neu_first_wave_df['has_bigrams'].sum()\n",
        "rows_with_trigrams = high_neu_first_wave_df['has_trigrams'].sum()\n",
        "rows_with_none     = (~high_neu_first_wave_df['has_bigrams'] & ~high_neu_first_wave_df['has_trigrams']).sum()\n",
        "\n",
        "# 4) Report\n",
        "print(f\"Rows with bigrams:   {rows_with_bigrams}\")\n",
        "print(f\"Rows with trigrams:  {rows_with_trigrams}\")\n",
        "print(f\"Rows with no n-grams: {rows_with_none}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6rqtjqNfkRe"
      },
      "outputs": [],
      "source": [
        "high_neu_first_wave_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTX0kETnfo-o"
      },
      "outputs": [],
      "source": [
        "# Print the total number of rows in the DataFrame\n",
        "total_rows = high_neu_first_wave_df.shape[0]\n",
        "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
        "\n",
        "# Check the number of rows in the 'trigram_tokenized' column\n",
        "print(f\"Number of rows in 'trigram_tokenized' column: {high_neu_first_wave_df['trigram_tokens'].shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4r1QsDEn5JI"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# 1) Flatten all trigram lists into one big sequence\n",
        "all_trigrams = itertools.chain.from_iterable(high_neu_first_wave_df['trigram_tokens'])\n",
        "\n",
        "# 2) Filter for genuine trigrams (exactly two underscores → three words joined)\n",
        "trigram_counts = Counter(\n",
        "    token for token in all_trigrams\n",
        "    if isinstance(token, str) and token.count('_') == 2\n",
        ")\n",
        "\n",
        "# 3) How many unique trigrams?\n",
        "total_unique_trigrams = len(trigram_counts)\n",
        "print(f\"Total number of unique trigrams: {total_unique_trigrams}\")\n",
        "\n",
        "# 4) Show the 10 most common trigrams\n",
        "print(\"\\nMost common trigrams:\")\n",
        "for trigram, count in trigram_counts.most_common(10):\n",
        "    print(f\"{trigram}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS1UskOufykm"
      },
      "outputs": [],
      "source": [
        "#import gensim.corpora as corpora\n",
        "# Create Dictionary\n",
        "#id2word = corpora.Dictionary(high_neu_first_wave_df['trigram_tokens'].tolist())\n",
        "\n",
        "## pruning\n",
        "#id2word.filter_extremes(no_below=5, no_above=0.5)\n",
        "\n",
        "#    (Optional) Re-map the remaining token IDs to remove gaps\n",
        "#id2word.compactify()\n",
        "\n",
        "# 2. Convert each document to a Bag-of-Words\n",
        "# texts = high_neu_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # Term Document Frequency\n",
        "# corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "# # View\n",
        "# print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZtXFSO7YotEU"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models.ldamodel import LdaModel\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# import nltk\n",
        "# ## Build the basic LDA model\n",
        "# lda_model = LdaModel(corpus=corpus,\n",
        "#                                        id2word=id2word,\n",
        "#                                        num_topics=3,\n",
        "#                                        random_state=100,\n",
        "#                                           chunksize=200,\n",
        "#                                        passes=50,\n",
        "#                                         iterations= 100,\n",
        "#                                        alpha='auto',\n",
        "#                                       eta='auto',\n",
        "#                                        per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GO7Y_w3Eo6IW"
      },
      "outputs": [],
      "source": [
        "# from pprint import pprint\n",
        "\n",
        "# # Print the Keyword in the 3 topics\n",
        "# pprint(lda_model.print_topics())\n",
        "# doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "_SPSr9cn5HtA",
        "outputId": "174f4685-d629-44b8-d3f5-820b8949609c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'high_neu_first_wave_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-dfa24a8c749e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhigh_neu_first_wave_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'high_neu_first_wave_df' is not defined"
          ]
        }
      ],
      "source": [
        "high_neu_first_wave_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsOdRORmpGnE"
      },
      "outputs": [],
      "source": [
        "# from gensim.models import CoherenceModel\n",
        "\n",
        "# # Compute Coherence Score\n",
        "# coherence_model_lda = CoherenceModel(model=lda_model, texts=high_neu_first_wave_df['trigram_tokenized'], dictionary=id2word, coherence='c_v')\n",
        "# coherence_lda = coherence_model_lda.get_coherence()\n",
        "# print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ASa22sYpPkJ"
      },
      "outputs": [],
      "source": [
        "# import pyLDAvis.gensim\n",
        "# import pickle\n",
        "# import pyLDAvis\n",
        "# import pyLDAvis.gensim_models as gensimvis\n",
        "# import pyLDAvis\n",
        "\n",
        "# # Assuming ldamodel, corpus, and dictionary are already defined\n",
        "# # Enable the automatic display of visualizations in Jupyter\n",
        "# pyLDAvis.enable_notebook()\n",
        "\n",
        "# # Prepare the LDA visualization directly\n",
        "# LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "\n",
        "# # Display the prepared visualization directly in the notebook\n",
        "# pyLDAvis.display(LDAvis_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tMA-H8JduCO"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Assuming high_pos_df['trigram_tokenized'] contains lists of lemmatized trigram tokens\n",
        "texts = high_neu_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# Create a Dictionary and Corpus\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Function to compute coherence and perplexity\n",
        "def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations, seed):\n",
        "    lda_model = LdaModel(corpus=corpus,\n",
        "                         id2word=dictionary,\n",
        "                         num_topics=num_topics,\n",
        "                         random_state=seed,\n",
        "                         chunksize=chunksize,\n",
        "                         passes=passes,\n",
        "                         iterations=iterations,\n",
        "                         alpha='auto',\n",
        "                         eta='auto',\n",
        "                         per_word_topics=True)\n",
        "\n",
        "    perplexity = lda_model.log_perplexity(corpus)\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = coherence_model_lda.get_coherence()\n",
        "\n",
        "     # Extract alpha and eta\n",
        "    alpha = lda_model.alpha\n",
        "    eta = lda_model.eta\n",
        "    return perplexity, coherence, alpha, eta\n",
        "\n",
        "# Define the parameter grid with your specific values\n",
        "seeds = [0, 1, 2]\n",
        "num_topics_range = range(2, 10)  # Adjust the range based on your needs\n",
        "chunksize_range = [1000]\n",
        "passes_range = [100, 200,260]\n",
        "iterations_range = [50,100, 200]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Grid search over all combinations of hyperparameters\n",
        "for seed in [0, 1, 2]:\n",
        " for num_topics, chunksize, passes, iterations in itertools.product(num_topics_range, chunksize_range, passes_range, iterations_range):\n",
        "    perplexity, coherence , alpha, eta = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations, seed)\n",
        "    results.append((num_topics, chunksize, passes, iterations, perplexity, coherence,alpha,eta,seed))\n",
        "    print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f} ,Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# Convert results to a DataFrame for better analysis\n",
        "results_df = pd.DataFrame(results, columns=['num_topics', 'chunksize', 'passes', 'iterations', 'perplexity', 'coherence','alpha','eta', 'seed'])\n",
        "# Add exponentiated perplexity column\n",
        "results_df['perplexity_exp'] = np.exp(-results_df['perplexity'])\n",
        "\n",
        "# Display results\n",
        "print(\"\\nResults:\")\n",
        "print(results_df)\n",
        "\n",
        "# Find the optimal number of topics with the highest coherence\n",
        "optimal_result = results_df.sort_values(\n",
        "    by=['coherence', 'perplexity_exp'],\n",
        "    ascending=[False, True]\n",
        ").iloc[0]\n",
        "optimal_num_topics = optimal_result['num_topics']\n",
        "optimal_chunksize = optimal_result['chunksize']\n",
        "optimal_passes = optimal_result['passes']\n",
        "optimal_iterations = optimal_result['iterations']\n",
        "optimal_perplexity = optimal_result['perplexity_exp']\n",
        "optimal_coherence = optimal_result['coherence']\n",
        "optimal_alpha = optimal_result['alpha']\n",
        "optimal_eta   = optimal_result['eta']\n",
        "optimal_seed = optimal_result['seed']\n",
        "\n",
        "print(f\"\\nOptimal Parameters:\")\n",
        "print(f\"Number of Topics: {optimal_num_topics}\")\n",
        "print(f\"Chunksize: {optimal_chunksize}\")\n",
        "print(f\"Passes: {optimal_passes}\")\n",
        "print(f\"Iterations: {optimal_iterations}\")\n",
        "print(f\"Coherence: {optimal_coherence:.4f}\")\n",
        "print(f\"Perplexity: {optimal_perplexity:.4f}\")\n",
        "print(f\" Alpha (per topic): {optimal_alpha}\")\n",
        "print(f\" Eta   (per word):  {optimal_eta}\")\n",
        "print(f\" seed:  {optimal_seed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7tC5hqNviVC"
      },
      "outputs": [],
      "source": [
        "# 1. Fit the model\n",
        "lda_opt = LdaModel(\n",
        "    corpus        = corpus,\n",
        "    id2word       = dictionary,\n",
        "    num_topics    = optimal_num_topics,\n",
        "    chunksize     = optimal_chunksize,\n",
        "    passes        = optimal_passes,\n",
        "    iterations    = optimal_iterations,\n",
        "    alpha         = 'auto',\n",
        "    eta           = 'auto',\n",
        "    random_state  = optimal_seed,\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "# 2. Extract metrics and priors\n",
        "opt_perp  = lda_opt.log_perplexity(corpus)\n",
        "opt_coh   = CoherenceModel(model=lda_opt, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
        "opt_alpha = lda_opt.alpha\n",
        "opt_eta   = lda_opt.eta\n",
        "\n",
        "print(f\"Re-fitted Optimal Model:\")\n",
        "print(f\" Coherence: {opt_coh:.4f}\")\n",
        "print(f\" Perplexity: {opt_perp:.4f}\")\n",
        "print(f\" Alpha (per topic): {opt_alpha}\")\n",
        "print(f\" Eta   (per word):  {opt_eta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lI4t6LJd6oV"
      },
      "outputs": [],
      "source": [
        "lda_opt.save('/content/drive/MyDrive/lda_model_neutral_4th_wave.gensim')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTw6J1MbvuyA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Grab your metrics & hyper‐params\n",
        "coherence_val  = opt_coh\n",
        "perplexity_val = opt_perp\n",
        "alpha_val      = opt_alpha\n",
        "eta_vals       = opt_eta  # full array\n",
        "\n",
        "# 2. Write them into a single text file\n",
        "with open('lda_model_full_summary.txt', 'w') as f:\n",
        "    f.write(\"Re-fitted Optimal Model:\\n\")\n",
        "    f.write(f\" Coherence:  {coherence_val:.4f}\\n\")\n",
        "    f.write(f\" Perplexity: {perplexity_val:.4f}\\n\")\n",
        "    f.write(f\" Alpha:      {alpha_val}\\n\")\n",
        "    f.write(\" Eta values:\\n\")\n",
        "    for eta in eta_vals:\n",
        "        f.write(f\"{eta}\\n\")\n",
        "\n",
        "# 3. Trigger the download\n",
        "files.download('lda_model_full_summary_1st_mild_neu.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQffKNyfv1fy"
      },
      "outputs": [],
      "source": [
        "# Cell 3: verify that the refit recovered the same priors\n",
        "import numpy as np\n",
        "\n",
        "print(\"Alpha match:\", np.allclose(optimal_alpha, opt_alpha))\n",
        "print(\"Eta   match:\", np.allclose(optimal_eta,   opt_eta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5zjHu4bv3LW"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "from pprint import pprint\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pyLDAvis\n",
        "\n",
        "# Cell 2: Print topics & sample document–topic distribution\n",
        "print(\"=== Topics ===\")\n",
        "pprint(lda_opt.print_topics())\n",
        "\n",
        "doc_topics = [lda_opt.get_document_topics(doc) for doc in corpus]\n",
        "print(\"\\nSample doc-topic distribution for doc 0:\")\n",
        "pprint(doc_topics[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBrSGFowv5x2"
      },
      "outputs": [],
      "source": [
        "# Cell 3: pyLDAvis visualization\n",
        "# (make sure you’ve run `%matplotlib inline` or enabled notebook output)\n",
        "pyLDAvis.enable_notebook()\n",
        "vis_data = gensimvis.prepare(lda_opt, corpus, dictionary)\n",
        "pyLDAvis.display(vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rQhophGv7l5"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Print the top 30 terms per topic\n",
        "print(\"\\n=== Top 30 terms per topic ===\")\n",
        "for topic_id, term_weights in lda_opt.show_topics(\n",
        "        num_topics=lda_opt.num_topics,\n",
        "        num_words=30,\n",
        "        formatted=False):\n",
        "    print(f\"Topic {topic_id + 1}:\")\n",
        "    for word, weight in term_weights:\n",
        "        print(f\"  {word} ({weight:.4f})\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKJ2VqkT1z5O"
      },
      "outputs": [],
      "source": [
        "# import gensim.corpora as corpora\n",
        "# # Create Dictionary\n",
        "# id2word = corpora.Dictionary(high_neu_first_wave_df['trigram_tokens'].tolist())\n",
        "\n",
        "# ## pruning\n",
        "# id2word.filter_extremes(no_below=5, no_above=0.7)\n",
        "\n",
        "# #    (Optional) Re-map the remaining token IDs to remove gaps\n",
        "# id2word.compactify()\n",
        "\n",
        "# # 2. Convert each document to a Bag-of-Words\n",
        "# texts = high_neu_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # # Term Document Frequency\n",
        "# corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "# # # View\n",
        "# print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hqcY9LQ13L0"
      },
      "outputs": [],
      "source": [
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models import LdaModel\n",
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import itertools\n",
        "\n",
        "\n",
        "# # Create a Dictionary and Corpus\n",
        "# dictionary = id2word\n",
        "\n",
        "\n",
        "# # Function to compute coherence and perplexity\n",
        "# def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations):\n",
        "#     lda_model = LdaModel(corpus=corpus,\n",
        "#                          id2word=dictionary,\n",
        "#                          num_topics=num_topics,\n",
        "#                          random_state=100,\n",
        "#                          chunksize=chunksize,\n",
        "#                          passes=passes,\n",
        "#                          iterations=iterations,\n",
        "#                          alpha='auto',\n",
        "#                          eta='auto',\n",
        "#                          per_word_topics=True)\n",
        "\n",
        "#     perplexity = lda_model.log_perplexity(corpus)\n",
        "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "#     coherence = coherence_model_lda.get_coherence()\n",
        "\n",
        "#      # Extract alpha and eta\n",
        "#     alpha = lda_model.alpha\n",
        "#     eta = lda_model.eta\n",
        "#     return perplexity, coherence, alpha, eta\n",
        "\n",
        "# # Define the parameter grid with your specific values\n",
        "# num_topics_range = range(2, 10)  # Adjust the range based on your needs\n",
        "# chunksize_range = [250]\n",
        "# passes_range = [100, 200,260]\n",
        "# iterations_range = [50,100, 200]\n",
        "\n",
        "# # Store results\n",
        "# results = []\n",
        "\n",
        "# # Grid search over all combinations of hyperparameters\n",
        "# for num_topics, chunksize, passes, iterations in itertools.product(num_topics_range, chunksize_range, passes_range, iterations_range):\n",
        "#     perplexity, coherence , alpha, eta = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics, chunksize, passes, iterations)\n",
        "#     results.append((num_topics, chunksize, passes, iterations, perplexity, coherence,alpha,eta))\n",
        "#     print(f\"Num Topics: {num_topics}, Chunksize: {chunksize}, Passes: {passes}, Iterations: {iterations}, Perplexity: {perplexity:.4f}, Coherence: {coherence:.4f} ,Alpha: {alpha}, Eta: {eta}\")\n",
        "\n",
        "# # Convert results to a DataFrame for better analysis\n",
        "# results_df = pd.DataFrame(results, columns=['num_topics', 'chunksize', 'passes', 'iterations', 'perplexity', 'coherence','alpha','eta'])\n",
        "# # Add exponentiated perplexity column\n",
        "# results_df['perplexity_exp'] = np.exp(-results_df['perplexity'])\n",
        "\n",
        "# # Display results\n",
        "# print(\"\\nResults:\")\n",
        "# print(results_df)\n",
        "\n",
        "# # Find the optimal number of topics with the highest coherence\n",
        "# optimal_result = results_df.sort_values(\n",
        "#     by=['coherence', 'perplexity_exp'],\n",
        "#     ascending=[False, True]\n",
        "# ).iloc[0]\n",
        "# optimal_num_topics = optimal_result['num_topics']\n",
        "# optimal_chunksize = optimal_result['chunksize']\n",
        "# optimal_passes = optimal_result['passes']\n",
        "# optimal_iterations = optimal_result['iterations']\n",
        "# optimal_perplexity = optimal_result['perplexity_exp']\n",
        "# optimal_coherence = optimal_result['coherence']\n",
        "# optimal_alpha = optimal_result['alpha']\n",
        "# optimal_eta   = optimal_result['eta']\n",
        "\n",
        "# print(f\"\\nOptimal Parameters:\")\n",
        "# print(f\"Number of Topics: {optimal_num_topics}\")\n",
        "# print(f\"Chunksize: {optimal_chunksize}\")\n",
        "# print(f\"Passes: {optimal_passes}\")\n",
        "# print(f\"Iterations: {optimal_iterations}\")\n",
        "# print(f\"Coherence: {optimal_coherence:.4f}\")\n",
        "# print(f\"Perplexity: {optimal_perplexity:.4f}\")\n",
        "# print(f\" Alpha (per topic): {optimal_alpha}\")\n",
        "# print(f\" Eta   (per word):  {optimal_eta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMRIIaY72Exz"
      },
      "outputs": [],
      "source": [
        "# # 1. Fit the model\n",
        "# lda_opt = LdaModel(\n",
        "#     corpus        = corpus,\n",
        "#     id2word       = dictionary,\n",
        "#     num_topics    = optimal_num_topics,\n",
        "#     chunksize     = optimal_chunksize,\n",
        "#     passes        = optimal_passes,\n",
        "#     iterations    = optimal_iterations,\n",
        "#     alpha         = 'auto',\n",
        "#     eta           = 'auto',\n",
        "#     random_state  = 100,\n",
        "#     per_word_topics=True\n",
        "# )\n",
        "\n",
        "# # 2. Extract metrics and priors\n",
        "# opt_perp  = lda_opt.log_perplexity(corpus)\n",
        "# opt_coh   = CoherenceModel(model=lda_opt, texts=texts, dictionary=dictionary, coherence='c_v').get_coherence()\n",
        "# opt_alpha = lda_opt.alpha\n",
        "# opt_eta   = lda_opt.eta\n",
        "\n",
        "# print(f\"Re-fitted Optimal Model:\")\n",
        "# print(f\" Coherence: {opt_coh:.4f}\")\n",
        "# print(f\" Perplexity: {opt_perp:.4f}\")\n",
        "# print(f\" Alpha (per topic): {opt_alpha}\")\n",
        "# print(f\" Eta   (per word):  {opt_eta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCZB6st-2Pso"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from google.colab import files\n",
        "\n",
        "# # 1. Grab your metrics & hyper‐params\n",
        "# coherence_val  = opt_coh\n",
        "# perplexity_val = opt_perp\n",
        "# alpha_val      = opt_alpha\n",
        "# eta_vals       = opt_eta  # full array\n",
        "\n",
        "# # 2. Write them into a single text file\n",
        "# with open('lda_model_full_summary.txt', 'w') as f:\n",
        "#     f.write(\"Re-fitted Optimal Model:\\n\")\n",
        "#     f.write(f\" Coherence:  {coherence_val:.4f}\\n\")\n",
        "#     f.write(f\" Perplexity: {perplexity_val:.4f}\\n\")\n",
        "#     f.write(f\" Alpha:      {alpha_val}\\n\")\n",
        "#     f.write(\" Eta values:\\n\")\n",
        "#     for eta in eta_vals:\n",
        "#         f.write(f\"{eta}\\n\")\n",
        "\n",
        "# # 3. Trigger the download\n",
        "# files.download('lda_model_full_summary.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKF22tx32Tvi"
      },
      "outputs": [],
      "source": [
        "# # Cell 3: verify that the refit recovered the same priors\n",
        "# import numpy as np\n",
        "\n",
        "# print(\"Alpha match:\", np.allclose(optimal_alpha, opt_alpha))\n",
        "# print(\"Eta   match:\", np.allclose(optimal_eta,   opt_eta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yM3g2mS2WqE"
      },
      "outputs": [],
      "source": [
        "# # Cell 1: Imports\n",
        "# from pprint import pprint\n",
        "# import pyLDAvis.gensim_models as gensimvis\n",
        "# import pyLDAvis\n",
        "\n",
        "# # Cell 2: Print topics & sample document–topic distribution\n",
        "# print(\"=== Topics ===\")\n",
        "# pprint(lda_opt.print_topics())\n",
        "\n",
        "# doc_topics = [lda_opt.get_document_topics(doc) for doc in corpus]\n",
        "# print(\"\\nSample doc-topic distribution for doc 0:\")\n",
        "# pprint(doc_topics[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuAAM3vw2cwT"
      },
      "outputs": [],
      "source": [
        "# # Cell 3: pyLDAvis visualization\n",
        "# # (make sure you’ve run `%matplotlib inline` or enabled notebook output)\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis_data = gensimvis.prepare(lda_opt, corpus, dictionary)\n",
        "# pyLDAvis.display(vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEyIlD872h33"
      },
      "outputs": [],
      "source": [
        "# # Cell 4: Print the top 30 terms per topic\n",
        "# print(\"\\n=== Top 30 terms per topic ===\")\n",
        "# for topic_id, term_weights in lda_opt.show_topics(\n",
        "#         num_topics=lda_opt.num_topics,\n",
        "#         num_words=30,\n",
        "#         formatted=False):\n",
        "#     print(f\"Topic {topic_id + 1}:\")\n",
        "#     for word, weight in term_weights:\n",
        "#         print(f\"  {word} ({weight:.4f})\")\n",
        "#     print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sph7uTgnpd0Z"
      },
      "outputs": [],
      "source": [
        "# ## FIND THE OPTIMAL TOPIC\n",
        "\n",
        "# import gensim\n",
        "# from gensim import corpora\n",
        "# from gensim.models import LdaModel\n",
        "# from gensim.models.coherencemodel import CoherenceModel\n",
        "# import pandas as pd\n",
        "\n",
        "# # Assuming high_neu_first_wave_df['lemmatized_bigrams'] contains lists of lemmatized bigram tokens\n",
        "# texts = high_neu_first_wave_df['trigram_tokens'].tolist()\n",
        "\n",
        "# # Create a Dictionary and Corpus\n",
        "# dictionary = corpora.Dictionary(texts)\n",
        "# corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# # Function to compute coherence and perplexity\n",
        "# def compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics):\n",
        "#     lda_model = LdaModel(corpus=corpus,\n",
        "#                                        id2word=dictionary,\n",
        "#                                        num_topics=num_topics,\n",
        "#                                        random_state=100,\n",
        "#                                           chunksize=200,\n",
        "#                                        passes=50,\n",
        "#                                         iterations= 100,\n",
        "#                                        alpha='auto',\n",
        "#                                       eta='auto',\n",
        "#                                        per_word_topics=True)\n",
        "#     perplexity = lda_model.log_perplexity(corpus)\n",
        "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "#     coherence = coherence_model_lda.get_coherence()\n",
        "#     return perplexity, coherence\n",
        "\n",
        "# # Testing different numbers of topics\n",
        "# results = []\n",
        "# for num_topics in range(2, 12):  # You can adjust the range based on your needs\n",
        "#     perplexity, coherence = compute_coherence_and_perplexity(corpus, dictionary, texts, num_topics)\n",
        "#     results.append((num_topics, perplexity, coherence))\n",
        "\n",
        "# # Display results\n",
        "# print(\"Num Topics | Perplexity | Coherence\")\n",
        "# for result in results:\n",
        "#     print(f\"{result[0]:10d} | {result[1]:10.4f} | {result[2]:10.4f}\")\n",
        "\n",
        "# # Optional: find the number of topics with the highest coherence\n",
        "# optimal_num_topics = sorted(results, key=lambda x: x[2], reverse=True)[0][0]\n",
        "# print(f\"Optimal Number of Topics: {optimal_num_topics}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN73PLy9GAEe"
      },
      "outputs": [],
      "source": [
        "# # Extracting and printing the top 30 salient terms for each topic\n",
        "# num_topics = lda_model.num_topics\n",
        "# num_words = 30\n",
        "\n",
        "# for idx, topic in lda_model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False):\n",
        "#     print(f\"Topic {idx + 1}:\")\n",
        "#     for word, weight in topic:\n",
        "#         print(f\"  {word} ({weight:.4f})\")\n",
        "#     print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}